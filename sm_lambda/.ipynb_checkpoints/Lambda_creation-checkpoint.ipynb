{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73e6157",
   "metadata": {},
   "source": [
    "### MLOps 에 필요한 Lambda file 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f909d",
   "metadata": {},
   "source": [
    "#### lambda-yolo5-training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a92e3",
   "metadata": {},
   "source": [
    "이 Lambda Function 은 lambda_docker 를 참조합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69c4003",
   "metadata": {},
   "source": [
    "#### lambda-check-acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9209d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir lambda-check-acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "670d4f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lambda-check-acc/lambda_function.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda-check-acc/lambda_function.py\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import tarfile\n",
    "from io import BytesIO\n",
    "import os\n",
    "import pickle\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "sm = boto3.client('sagemaker')\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "\n",
    "acc_col_num = os.environ['ACC_COL_NUM']\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # print(event)    \n",
    "    model_data_url = event['model_data_url']\n",
    "    bucket = event['bucket']\n",
    "    key_value = model_data_url.split(bucket)[1][1:]\n",
    "    print(key_value)\n",
    "    tar_file_obj = s3.get_object(Bucket=bucket, Key=key_value)\n",
    "    tar_content = tar_file_obj ['Body'].read()\n",
    "    \n",
    "    accuracy = 0\n",
    "    \n",
    "    with tarfile.open(fileobj = BytesIO(tar_content)) as tar:\n",
    "      for tar_resource in tar:\n",
    "          if (tar_resource.isfile()):\n",
    "            # if \"txt\" in tar_resource.name:\n",
    "            #     inner_file_bytes = tar.extractfile(tar_resource).read()\n",
    "            #     print(inner_file_bytes)\n",
    "            #     accuracy = inner_file_bytes.decode('utf-8')\n",
    "            if \"results.csv\" in tar_resource.name:\n",
    "                inner_file_bytes = tar.extractfile(tar_resource).read()\n",
    "                file_data = inner_file_bytes.decode('utf-8')\n",
    "                file = StringIO(file_data)\n",
    "                csv_data = csv.reader(file, delimiter=\",\")\n",
    "                \n",
    "                max_line = len(list(csv_data))\n",
    "                \n",
    "                file = StringIO(file_data)\n",
    "                csv_data = csv.reader(file, delimiter=\",\")\n",
    "                \n",
    "                line_count = 0\n",
    "                \n",
    "                for row in csv_data:\n",
    "                    line_count += 1\n",
    "                    if line_count == max_line:\n",
    "                        accuracy = row[int(acc_col_num)].lstrip()\n",
    "                        \n",
    "    print(\"accuracy is \" + accuracy)\n",
    "    \n",
    "    desired_accuracy = event['desired_accuracy']\n",
    "    \n",
    "    if accuracy > desired_accuracy:\n",
    "        event['train_result'] = \"PASS\"\n",
    "        print(\"PASS\")\n",
    "    else:\n",
    "        event['train_result'] = \"FAIL\"\n",
    "        print(\"FAIL\")\n",
    "\n",
    "    return event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd62584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: lambda-check-acc/ (stored 0%)\n",
      "  adding: lambda-check-acc/lambda_function.py (deflated 66%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r lambda-check-acc.zip lambda-check-acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a3f14",
   "metadata": {},
   "source": [
    "#### lambda-sf-trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b45b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir lambda-sf-trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c4dfe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lambda-sf-trigger/lambda_function.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda-sf-trigger/lambda_function.py\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "sf = boto3.client('stepfunctions')\n",
    "\n",
    "\n",
    "state_machine_arn = os.environ['STATE_MACHINE_ARN']\n",
    "desired_accuracy = os.environ['DESIRED_ACCURACY']\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    print(event)\n",
    "    bucket_name = event['Records'][0]['s3']['bucket']['name']\n",
    "    file_key = event['Records'][0]['s3']['object']['key']\n",
    "    print('Reading {} from {}'.format(file_key, bucket_name))\n",
    "    \n",
    "    # obj = s3.get_object(Bucket = bucket_name, Key = file_key)\n",
    "    \n",
    "    # file_content = obj['Body'].read().decode('utf-8')\n",
    "    json_string = {\n",
    "        \"desired_accuracy\": desired_accuracy\n",
    "    }\n",
    "    \n",
    "    # json_content = json.loads(json_string)\n",
    "    print(json_string)\n",
    "    \n",
    "    sf.start_execution(\n",
    "        stateMachineArn = state_machine_arn,\n",
    "        input = json.dumps(json_string))\n",
    "    \n",
    "    return event\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3eaad59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: lambda-sf-trigger/ (stored 0%)\n",
      "  adding: lambda-sf-trigger/lambda_function.py (deflated 49%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r lambda-sf-trigger.zip lambda-sf-trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63beb6a8",
   "metadata": {},
   "source": [
    "#### lambda-await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "240c0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir lambda-await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "715adc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lambda-await/lambda_function.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda-await/lambda_function.py\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "\n",
    "sagemaker       = boto3.client('sagemaker')\n",
    "cfn_client      = boto3.client('cloudformation')\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    stage = event['stage']\n",
    "\n",
    "    if stage == 'Training':\n",
    "        training_job_name = event['training_job_name']\n",
    "        training_details = describe_training_job(training_job_name)\n",
    "        print(training_details)\n",
    "\n",
    "        status = training_details['TrainingJobStatus']\n",
    "        if status == 'Completed':\n",
    "            s3_output_path = training_details['OutputDataConfig']['S3OutputPath']\n",
    "            model_data_url = os.path.join(s3_output_path, training_details['TrainingJobName'], 'output/model.tar.gz')\n",
    "\n",
    "            event['message'] = 'Training job \"{}\" complete. Model data uploaded to \"{}\"'.format(training_job_name, model_data_url)\n",
    "            event['model_data_url'] = model_data_url\n",
    "            event['training_job'] = training_details['TrainingJobName']\n",
    "        elif status == 'Failed':\n",
    "            failure_reason = training_details['FailureReason']\n",
    "            event['message'] = 'Training job failed. {}'.format(failure_reason)\n",
    "    \n",
    "    event['status'] = status\n",
    "    \n",
    "    print(event)\n",
    "    \n",
    "    return event\n",
    "\n",
    "def describe_training_job(name):\n",
    "    \"\"\" Describe SageMaker training job identified by input name.\n",
    "    Args:\n",
    "        name (string): Name of SageMaker training job to describe.\n",
    "    Returns:\n",
    "        (dict)\n",
    "        Dictionary containing metadata and details about the status of the training job.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = sagemaker.describe_training_job(\n",
    "            TrainingJobName = name\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Unable to describe training job.')\n",
    "        raise(e)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aac4bd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: lambda-await/ (stored 0%)\n",
      "  adding: lambda-await/lambda_function.py (deflated 64%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r lambda-await.zip lambda-await"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855dfbcc",
   "metadata": {},
   "source": [
    "#### lambda-model-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89f1e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir lambda-model-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e75b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lambda-model-registry/lambda_function.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda-model-registry/lambda_function.py\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import botocore\n",
    "import os\n",
    "\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "model_package_group_name = os.environ['MODEL_PACKAGE_GROUP_NAME']\n",
    "model_package_group_desc = os.environ['MODEL_PACKAGE_GROUP_DESC']\n",
    "\n",
    "# training_image = '366743142698.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'\n",
    "training_image = os.environ['ECR_IMAGE_URI']\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    modelpackage_inference_specification =  {\n",
    "        \"InferenceSpecification\": {\n",
    "          \"Containers\": [\n",
    "             {\n",
    "                \"Image\": training_image,\n",
    "             }\n",
    "          ],\n",
    "          \"SupportedContentTypes\": [ \"application/x-image\" ],\n",
    "          \"SupportedResponseMIMETypes\": [ \"application/x-image\" ],\n",
    "        }\n",
    "    }\n",
    "     \n",
    "    model_data_url = event['model_data_url'] \n",
    "    \n",
    "    \n",
    "    # Specify the model data\n",
    "    modelpackage_inference_specification[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"]=model_data_url\n",
    "    \n",
    "    create_model_package_input_dict = {\n",
    "        \"ModelPackageGroupName\" : model_package_group_name,\n",
    "        \"ModelPackageDescription\" : model_package_group_desc,\n",
    "        \"ModelApprovalStatus\" : \"PendingManualApproval\"\n",
    "    }\n",
    "\n",
    "    create_model_package_input_dict.update(modelpackage_inference_specification)\n",
    "    modelpackage_inference_specification[\"InferenceSpecification\"][\"Containers\"][0]\n",
    "    \n",
    "    try:\n",
    "        create_mode_package_response = sm_client.create_model_package(**create_model_package_input_dict)\n",
    "    except botocore.exceptions.ClientError as ce:\n",
    "        # When model package group does not exit\n",
    "        print('Model package grop does not exist. Creating a new one')\n",
    "        if ce.operation_name == \"CreateModelPackage\":\n",
    "            if ce.response[\"Error\"][\"Message\"] == \"Model Package Group does not exist.\":\n",
    "                # Create model package group\n",
    "                create_model_package_group_response = sm_client.create_model_package_group(\n",
    "                    ModelPackageGroupName=model_package_group_name,\n",
    "                    ModelPackageGroupDescription=model_package_group_desc,\n",
    "                )\n",
    "                \n",
    "                create_mode_package_response = sm_client.create_model_package(**create_model_package_input_dict)\n",
    "                \n",
    "    return event\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9b49e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: lambda-model-registry/ (stored 0%)\n",
      "  adding: lambda-model-registry/lambda_function.py (deflated 66%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r lambda-model-registry.zip lambda-model-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442bfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
